{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c58245f",
   "metadata": {},
   "source": [
    "# Phase 6: Proactive Pattern Detection\n",
    ">_(Part of the Data Science lifecycle for uncovering high-risk clusters & anomalies)_\n",
    "\n",
    "#### **Objective:**\n",
    "Use **unsupervised learning** techniques to surface _hidden structure_, such as:\n",
    "* **Alias clusters** (e.g. same entity across alt names)\n",
    "* **Outlier behavior** (e.g. odd country associations)\n",
    "* **Potential identity masking** strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40277631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c0f5fb",
   "metadata": {},
   "source": [
    "#### **Load & Prepare Features:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d95f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_match\n",
      "1    12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/sanctions_features.csv\")\n",
    "df = df[df[\"fuzz_ratio_reference\"].notna()].copy()\n",
    "\n",
    "df[\"is_match\"] = ((df[\"fuzz_ratio\"] > 75) & (df[\"common_token_count\"] > 0)).astype(int)\n",
    "\n",
    "matched_df = df[df[\"is_match\"] == 1].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ca6b73",
   "metadata": {},
   "source": [
    "#### **Clustering for Alias Networks (DBSCAN):**\n",
    "\n",
    "Normalize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba27cbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00 -1.42108547e-14  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.42108547e-14  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.42108547e-14  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.42108547e-14  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.42108547e-14  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.42108547e-14  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.42108547e-14  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.42108547e-14  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.42108547e-14  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.42108547e-14  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.42108547e-14  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.42108547e-14  0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "features = [\"length_diff\", \"fuzz_ratio\", \"common_token_count\", \"word_count\"]\n",
    "X = StandardScaler().fit_transform(matched_df[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15707829",
   "metadata": {},
   "source": [
    "Run DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e3e41ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=0.8, min_samples=3).fit(X)\n",
    "matched_df[\"cluster\"] = db.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3859d24f",
   "metadata": {},
   "source": [
    "Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5d8c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\xampp\\htdocs\\data-engineering\\ofac-end-to-end-data-project\\sanction-risk-ml\\venv\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:648: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=X_pca[:, 0], hue=matched_df[\"cluster\"], palette=\"tab10\")\n",
    "plt.title(\"Alias Clusters via DBSCAN\")\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
